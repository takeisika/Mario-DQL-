{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a60761-827b-4519-b412-648033dcf88f",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size: 50px\">Gym 0.24version Demo </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be429b28-6215-4145-b9a6-b188ad95264b",
   "metadata": {},
   "source": [
    "<h1>General Set Up</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "477620d9-0dac-40c8-8612-8711a860abcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: gym-super-mario-bros 7.3.0\n",
      "Uninstalling gym-super-mario-bros-7.3.0:\n",
      "  Successfully uninstalled gym-super-mario-bros-7.3.0\n",
      "Found existing installation: nes-py 8.2.1\n",
      "Uninstalling nes-py-8.2.1:\n",
      "  Successfully uninstalled nes-py-8.2.1\n",
      "Collecting gym_super_mario_bros==7.3.0\n",
      "  Using cached gym_super_mario_bros-7.3.0-py2.py3-none-any.whl (198 kB)\n",
      "Collecting nes_py\n",
      "  Using cached nes_py-8.2.1-cp39-cp39-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: tqdm>=4.48.2 in ./opt/anaconda3/lib/python3.9/site-packages (from nes_py) (4.62.3)\n",
      "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in ./opt/anaconda3/lib/python3.9/site-packages (from nes_py) (1.5.21)\n",
      "Requirement already satisfied: gym>=0.17.2 in ./opt/anaconda3/lib/python3.9/site-packages (from nes_py) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./opt/anaconda3/lib/python3.9/site-packages (from nes_py) (1.24.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from gym>=0.17.2->nes_py) (2.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in ./opt/anaconda3/lib/python3.9/site-packages (from gym>=0.17.2->nes_py) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in ./opt/anaconda3/lib/python3.9/site-packages (from gym>=0.17.2->nes_py) (6.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gym>=0.17.2->nes_py) (3.6.0)\n",
      "Installing collected packages: nes-py, gym-super-mario-bros\n",
      "Successfully installed gym-super-mario-bros-7.3.0 nes-py-8.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y gym_super_mario_bros nes_py\n",
    "!pip install gym_super_mario_bros==7.3.0 nes_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e88a6f56-bd06-4aef-b995-15b2ec54cd86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: gym 0.26.0\n",
      "Uninstalling gym-0.26.0:\n",
      "  Successfully uninstalled gym-0.26.0\n",
      "Collecting gym==0.24\n",
      "  Using cached gym-0.24.0-py3-none-any.whl\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in ./opt/anaconda3/lib/python3.9/site-packages (from gym==0.24) (6.1.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in ./opt/anaconda3/lib/python3.9/site-packages (from gym==0.24) (1.24.3)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in ./opt/anaconda3/lib/python3.9/site-packages (from gym==0.24) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from gym==0.24) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gym==0.24) (3.6.0)\n",
      "Installing collected packages: gym\n",
      "Successfully installed gym-0.24.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall gym -y\n",
    "!pip install gym==0.24\n",
    "#installしたら一旦、kernel shut downしてgym version check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f5f513-7bbc-4eec-9b6f-80675eff33fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishikawatakehiro/opt/anaconda3/lib/python3.9/site-packages/gym/envs/registration.py:423: UserWarning: \u001b[33mWARN: Custom namespace `ALE` is being overridden by namespace `ALE`. If you are developing a plugin you shouldn't specify a namespace in `register` calls. The namespace is specified through the entry point package metadata.\u001b[0m\n",
      "  logger.warn(\n",
      "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "print(gym.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40dc754-59e1-4417-8c8a-b8440358a6ee",
   "metadata": {},
   "source": [
    "<h1>Set Up For Basic Practice</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb68e01-0ef9-4f2b-ba95-63bc9d7a8253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym_super_mario_bros #Mario環境\n",
    "from nes_py.wrappers import JoypadSpace #simpified controller (controller buttonの数を減らす)\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT #simplified command (A button+B button+R button, etc多変だから)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a42b4c9-29ff-4088-a302-80dbc9283970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishikawatakehiro/opt/anaconda3/lib/python3.9/site-packages/gym/envs/registration.py:568: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/ishikawatakehiro/opt/anaconda3/lib/python3.9/site-packages/gym/envs/registration.py:619: UserWarning: \u001b[33mWARN: Env check failed with the following message: Calling the reset method with `return_info=True` did not return a 2-tuple\n",
      "You can set `disable_env_checker=True` to disable this check.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "#上記を実際にset #gym0.26versionの場合は、env = gym_super_mario_bros.make('SuperMarioBros-v0',apply_api_compatibility=True, render_mode=\"human\")\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2796b9b3-52a1-49b6-9685-4baa6ec37695",
   "metadata": {},
   "source": [
    "<h1>Mario Basic Practice</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b751f98-dbe8-4c69-8e70-3c059c70a043",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 19:06:46.929 python[53156:1205803] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fa48b30ebc0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2023-08-02 19:06:46.930 python[53156:1205803] Warning: Expected min height of view: (<NSButton: 0x7fa48b305660>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2023-08-02 19:06:46.931 python[53156:1205803] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fa48b308e50>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2023-08-02 19:06:46.932 python[53156:1205803] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fa48b31e700>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n"
     ]
    }
   ],
   "source": [
    "done = True #1行目にdone=Trueを置いておくことで、ensure最初のstepがenv.reset()される\n",
    "\n",
    "for step in range(100): \n",
    "    \n",
    "    if done: #最初のstep\n",
    "        env.reset()\n",
    "\n",
    "    #doneがTrueであろうがFalseであろうが以下の処理\n",
    "    state, reward, done, info = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4be3ca0-aedd-4ccf-ab78-078d711f7353",
   "metadata": {},
   "source": [
    "<h1>Advanced Set Up</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "378e0613-379b-4abe-adb4-e7e697bd84d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./opt/anaconda3/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in ./opt/anaconda3/lib/python3.9/site-packages (0.15.2)\n",
      "Requirement already satisfied: torchaudio in ./opt/anaconda3/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: filelock in ./opt/anaconda3/lib/python3.9/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: sympy in ./opt/anaconda3/lib/python3.9/site-packages (from torch) (1.9)\n",
      "Requirement already satisfied: networkx in ./opt/anaconda3/lib/python3.9/site-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: typing-extensions in ./opt/anaconda3/lib/python3.9/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: jinja2 in ./opt/anaconda3/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.9/site-packages (from torchvision) (2.29.0)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.9/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./opt/anaconda3/lib/python3.9/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (3.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "#pytorchとstable baselinesをtutorial codeにてinstallしようとしたら、not available\n",
    "#python versionが最新過ぎて(不可逆的にjupiterでは3.9)、対応するpytorchとstable baselinesが見当たらない\n",
    "#とりあえず、version specifyせずに、installしてみることにする...\n",
    "# Install stable baselines for RL stuff\n",
    "!pip install torch torchvision torchaudio \n",
    "!pip install \"stable-baselines3[extra]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c06dd36-c227-46e6-9cb3-0ccab188eaef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishikawatakehiro/opt/anaconda3/lib/python3.9/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:326: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  np.bool8: (False, True),\n",
      "2023-08-02 19:06:57.579477: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/ishikawatakehiro/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:246: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  np.bool8: (False, True),\n",
      "/Users/ishikawatakehiro/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:  2.0.1\n",
      "Stable Baselines3 version:  2.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch  #importing a super brain (PyTorch) for your AI.\n",
    "import stable_baselines3 #importing a book of strategies (Stable Baselines3) for your AI\n",
    "\n",
    "print(\"PyTorch version: \", torch.__version__)\n",
    "print(\"Stable Baselines3 version: \", stable_baselines3.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfbaaf26-e5df-429b-a96f-85badd364287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gym.wrappers import GrayScaleObservation #Preprocessing: imageをRGBcolorからGrayscaleへとconvertすることにより、処理しやすく\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "#importしたa book of strategies (Stable Baselines3) for your AIからVecFrameStack, DummyVecEnvを参照\n",
    "\n",
    "#・DummyVecEnv:\n",
    "#教室にて、先生がたくさんの生徒に共通のtaksを授業内にてやらせる (workbookのpage Aからpage Bまでみたいな)\n",
    "#先生はそれぞれの生徒が取り組んでる課題を全て把握 (yet生徒個々のexperienceは違くなるかもだけど、ある生徒はすぐtask終わる一方、他の人は憤慨)\n",
    "#こうすることにより、複数の生徒を同時に学習させることが出来る\n",
    "#DummyVecEnvなしだと、ひとりしか生徒教えられない\n",
    "\n",
    "#・VecFrameStack:\n",
    "#a memory book that allows the AI to remember and consider several past events (frames), not just the most recent one.\n",
    "#robotにballをcatchする動作を教える時に、ballの画像1枚じゃ都合が悪い、ballが落下する最後の複数枚の画像を学習に活用することにより\n",
    "#そのballの軌道を効率的に教えることが出来る。\n",
    "#単純に、静止画1枚じゃ、ball catchする際にballの軌道予測するの無理でしょ\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1575b67-5208-4587-b2a2-7ead9b553085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishikawatakehiro/opt/anaconda3/lib/python3.9/site-packages/gym/envs/registration.py:568: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/ishikawatakehiro/opt/anaconda3/lib/python3.9/site-packages/gym/envs/registration.py:619: UserWarning: \u001b[33mWARN: Env check failed with the following message: Calling the reset method with `return_info=True` did not return a 2-tuple\n",
      "You can set `disable_env_checker=True` to disable this check.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/ishikawatakehiro/opt/anaconda3/lib/python3.9/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0') #この時点にてenvは、RGB format with shape (240, 256, 3)\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "#上記2行basic practice時に、すでにmakeしてるから任意だけど、advanced practiceだけ試したい時用\n",
    "\n",
    "env = GrayScaleObservation(env, keep_dim=True) #この時点にてenvは、grayscale format with shape (240, 256, 1)\n",
    "#RGBcolorをGrayScaleに変換してdataのdimensionを下げることにより、RLの処理を高める\n",
    "\n",
    "#env = gym_super_mario_bros.make('SuperMarioBros-v0')だけだと、env = DummyVecEnv([lambda: env])をかけた時、AttributeError: 'SuperMarioBrosEnv' object has no attribute 'render_mode'が出る\n",
    "#だから無理やり、'SuperMarioBrosEnv' objectにinitにて'render_mode' attribute加える\n",
    "class CustomWrapper(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(CustomWrapper, self).__init__(env)\n",
    "        self.render_mode = 'human'  # add this line\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        observation, reset_info = super().reset(), {}\n",
    "        #print(f\"observation type: {type(observation)}, shape: {observation.shape}\") #結果: observation type: <class 'numpy.ndarray'>, shape: (240, 256, 1)\n",
    "        return observation, reset_info\n",
    "    \n",
    "    def step(self, action): #ValueError: not enough values to unpack (expected 5, got 4)なので追加必要 #DummyVecEnv expect 5values but gym 0.24 step() returns only 4 values\n",
    "        observation, reward, done, info = self.env.step(action)\n",
    "        return observation, reward, done, info, {} # Return an empty dictionary instead of None\n",
    "\n",
    "env = CustomWrapper(env)\n",
    "\n",
    "\n",
    "\n",
    "#wrapperを一度通っちゃうと、obsevationのformatが変わっちゃって、grayscaleが出来なくなっちゃう\n",
    "#だからenv = GrayScaleObservation(env, keep_dim=True)はwrapperの前に置く\n",
    "###e.g.###\n",
    "\n",
    "#wrapper内のformat\n",
    "#・observation type: <class 'numpy.ndarray'>, shape: (240, 256, 1)\n",
    "#・上記のprint(f\"observation type: {type(observation)}, shape: {observation.shape}\")によって確認可能\n",
    "\n",
    "#wrapper後のformat\n",
    "#・Observation after CustomWrapper type: <class 'tuple'>, structure: (array([[[104, 136, 252],・・・etc, [228,  92,  16]]], dtype=uint8), {})\n",
    "#・下記のprintによって確認可能\n",
    "#custom_state = env.reset()\n",
    "#print(f\"Observation after CustomWrapper type: {type(custom_state)}, structure: {custom_state}\")\n",
    "\n",
    "\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env, 4, channels_order='last')\n",
    "#今回はthe most recent oneだけでなく、最後の\"4\"frameをrememberする指定 #ここでいうframeとは、gameにおける場面毎のscreenshot\n",
    "\n",
    "#DummyVecEnv->VecFrameStackの順番が大事\n",
    "#教室にて生徒に共通taskさせる環境を整えてから、最後の複数枚画像(not静止画1枚)を、教育することにより、生徒に同時にたくさん教え込むことが出来る"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370db178-5e2a-40fe-acd2-7374fb3ce8ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1>Progress Of Advanced Set Up</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16f7d30-18b3-40ca-bcd5-460f13658190",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 240, 256, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###⭐️以下の2点を図示して確認したい⭐️###\n",
    "#・VecFrameStack wrapperにて最後の4枚とmemoryと指定したから、stateは4枚のconsecutive images(4枚のgame screenshots)が入ってる\n",
    "#・state = env.reset()したから、今回はenv.reset()した状態の1枚(4th)を除き、それより前の1~3thはresetされてるから見れない\n",
    "\n",
    "state = env.reset()\n",
    "state, reward, done, info = env.step([5])\n",
    "#VecFrameStack wrapperにて最後の4枚とmemoryと指定したから、stateは4枚のconsecutive images(4枚のgame screenshots)が入ってる\n",
    "#state = env.reset()したから、今回はenv.reset()した状態の1枚(4th)を除き、それより前の1~3thはresetされてるから見れない\n",
    "\n",
    "###stateが(batch size, width, height, channel)のimage dataである事を確認###\n",
    "print(state.shape)\n",
    "#stateはscreenshotsのimage dataだから、(batch size, width, height, channel) #result: (1, 240, 256, 4)\n",
    "#->(batchsize1個(the latest memory4枚にて1セット), 240width, 256height, channel4)\n",
    "\n",
    "#このstateに入ってる4枚のconsecutive imagesにおける、例えば、2枚目とかを見るためにはどうすれば良いだろう\n",
    "#state[1]だと、それは2nd envの状態を示すから違う。\n",
    "#cf.state[0]は1st envつまりenv.reset時。そこからaction取ったり、何らかの事情にてstatusが変わる毎にenvが更新\n",
    "#今回は、最初のreset時における1st state(state[0])が持つ4つのconsecutive imagesのうち、例えば、2番目が欲しい\n",
    "#answer: state[0][:,:,1]\n",
    "#4枚全部表示したい時はidxなどを使い・・・\n",
    "for idx in range(4):\n",
    "    plt.subplot(1,4,idx+1) #1row 4columnのsubplotで、idxは1個ずつ順番にshowの意味\n",
    "    plt.imshow(state[0][:,:,idx])\n",
    "plt.show()\n",
    "#resetしたstate(state[0])が持つconsecutive4枚のうち、\n",
    "#4枚目はreset瞬間だから表示されるけど、それより前のthe last 3imagesはresetされたから、memory消えてて表示されない\n",
    "#point: VecFrameStack(env, 4, channels_order='last')にて、最後4枚の記憶と指定した\n",
    "\n",
    "#あれさっき、grayscaleにしたのに何でgreenぽいのが表示?? grayと別に指定しない限りは、redかgreenかblueかgrayのいずれかどれでも良いからone color\n",
    "#grayかは分からないけど、1色というのが肝\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#state[0]: All pixel data from the first batch of images.\n",
    "#state[0][2]: The third line of pixels from each image in the first batch. 3列目\n",
    "#state[0][:,:,2]: All pixels from the third channel (image) in the first batch. 3枚目\n",
    "\n",
    "#state[0] selects all data from the first batch of images.\n",
    "#state[0][2,2] then selects a specific pixel located at the third row and third column in each of the 4 images in this batch.\n",
    "\n",
    "#(1, 240, 256, 4). This shape indicates:\n",
    "#There is 1 image batch in the state.\n",
    "#Each image has a resolution of 240 pixels in height and 256 pixels in width.\n",
    "#Each pixel in an image has 4 values, one for each color channel (in your case, grayscale values of 4 consecutive frames).\n",
    "#だから、state[0][239, 255]まで可能\n",
    "#⭐️image pixel dataは縦に240pixel 横に256pixelで成立している⭐️\n",
    "#⭐️だから、state[0][:,:] all of the the pixels in height (total240) and width (total256) in each of the 4 images in this batch⭐️\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#state[0][:,:]だけでplotすると、結果的には、state[0]が持つ4枚のimageの内、1st imageだけを4回表示する\n",
    "#eachに表示しないとだからidxが必要\n",
    "#for idx in range(4):\n",
    "    #plt.subplot(1,4,idx+1) #1row 4columnのsubplotで、idxは1個ずつ順番にshowの意味\n",
    "    #plt.imshow(state[0][:,:]) #<-ココ\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "###channelについて###\n",
    "#image processingだとchannelは4までしかない、channel1はgray、channel3がRGB、channel4がRGB+alpha(opacity etc)\n",
    "#RLだと、channelは無限にある、channelの数がstateが持つframe数を示す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1e281c-588a-403f-8197-a2beeba7c8a2",
   "metadata": {},
   "source": [
    "<h1>Train Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e81df769-59d9-4fe2-8b2e-46a89b163137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "from stable_baselines3 import PPO\n",
    "#Deep Q-learningはいちいちQ-value出す一方、PPOはQ-valueいちいち出さずに直接decision決める。\n",
    "#だから、large dataの時は、PPOの方がtypically都合良い\n",
    "#単純な⭕️❌gameみたいなのはQ-learningだけど、roboticsとかもっと複雑なgameとかにはPPOが良い\n",
    "#ちなみにPPOはlarge data deal出来るけど、put it the other way around、その分、trainingにdataいっぱい必要+時間かかる\n",
    "\n",
    "###PPO the easiest example (PPOでは、policyに沿って行動を起こす、そしてpolicyは経験を基にupdateされる)###\n",
    "#1D空間にて、A(左)地点からstartして、B(右)地点にて旗を回収。さらに、終了時間に体力消費が最小だとreward貰える。というgameがあったとする\n",
    "#最初、robotはB地点に辿り着くために、\"all the time move right\"というpolicyを基に行動を起こす\n",
    "#しかし、一度B地点に辿り着くと、体力消費までもrewardに影響することに気付く\n",
    "#だからpolicyを\"until the B地点、all the time move right. stop at the B地点\"に変更\n",
    "#みたいな感じにてpolicyがupdateされていく\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "#callbackとは値を返してもらう的な\n",
    "#train中においてeach time resultのfeedbackみたいなのをしてもらう(下記)\n",
    "#| time/                   |               |\n",
    "#|    fps                  | 19            |\n",
    "#|    iterations           | 2             |\n",
    "#|    time_elapsed         | 51            |\n",
    "#|    total_timesteps      | 1024  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95f68b84-09f7-4010-8f0c-016d37a2f1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback): #importしたBaseCallbackが親class\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1): #verboseは何も値返ってこなかったら、1というようにset\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        #何で、verboseだけselfみたいにせず、わざわざsuper()にしてる??\n",
    "        #check_freqとsave_pathはここで初めて新しく定義してるからsuper()しない\n",
    "        #ただ、verboseはnew bornじゃなく、親クラスから継承してきたものだから、こっちで使おうと思ったらsuper()いる\n",
    "\n",
    "        \n",
    "    def _init_callback(self): #callback始まったらこのmethodが始まる\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "        #もしsave_pathが新出だったら、go ahead create directories for that path\n",
    "        #でも、もしsave_path is not new. error出さずにdo nothing and move on (exist_ok=True)\n",
    "\n",
    "        \n",
    "        \n",
    "    def _on_step(self): #check_freq(10000)毎のstepする度にこのmethod発動 (下記のifにて指定)\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "        #check_freq(10000)毎のstep結果毎にcallback行う\n",
    "        #ここで if self.n_calls == self.check_freqとしないのは、それだとcallbackが一度しか行われないから\n",
    "        \n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            #'best_model_{}'の{}をvalue of self.n_callsにてreplace\n",
    "            \n",
    "            self.model.save(model_path)\n",
    "            #self.modelのmodelは下記でcreateしたmodel\n",
    "            #以下にてmodel.learnをやった時点にてStable Baselines3が自動的にself.model創るから、initにてself.save_pathみたいにしなくて良い\n",
    "\n",
    "        return True #trainingはfalse来るとstopするけど、pythonはdefaultにてfalse返すから、ここでtrue returnするようにsetしないとstep()はonce動いてstopする\n",
    "\n",
    "    \n",
    "CHECKPOINT_DIR = './train/'\n",
    "#trainingは最後のものがbestとは限らない、途中にてもっと質高いものがあった場合、それを引き抜くことも可能\n",
    "#さらに、これらはbackup的な副次的meritにもなる\n",
    "#model_path = './train/best_model_xxxxx'にtrainしたmodelのxxxxx step count trained分が保存されてる\n",
    "#model = PPO.load(model_path)としてobtainすることが可能\n",
    "\n",
    "LOG_DIR = './logs/'\n",
    "#callbackしたものを別サイトにてもっと見やすいversionにて閲覧可能tensorboard --logdir=./logs/というcommandをterminalにてtry\n",
    "\n",
    "\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)\n",
    "#check_freq(10000)毎のstep結果をsave_path(CHECKPOINT_DIR)にてsaveしている\n",
    "\n",
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001, n_steps=512) \n",
    "#・CNNs用のPPO\n",
    "#・verbose=1じゃなくてverbose=0だったら下みたいにlogの表示はされない\n",
    "#・n_steps=512: step512毎に強制的にPPOのpolicyがupdateされる\n",
    "#・tensorboard_log=LOG_DIR: terminalにてtensorboard --logdir=./logs/というcommand打つとhttp://localhost:6006/#timeseriesみたいなURL get\n",
    "#->URLgetしたら、そのpageにてもっとグラフ推移color versionのtrain進行報告が見れる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7fda5975-5564-4fb0-b3f7-4858c1607f73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/PPO_4\n",
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 77  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 6   |\n",
      "|    total_timesteps | 512 |\n",
      "----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 23           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 1024         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.378947e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.596        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | 0.596        |\n",
      "|    value_loss           | 0.000956     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 17            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 89            |\n",
      "|    total_timesteps      | 1536          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.8789738e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | nan           |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 8.61e-07      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | 0             |\n",
      "|    value_loss           | 0.000979      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 16            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 127           |\n",
      "|    total_timesteps      | 2048          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1198066e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | 0.938         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | -0.426        |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.426        |\n",
      "|    value_loss           | 0.000535      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 15           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 2560         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.075708e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 7.31e-09     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | 0            |\n",
      "|    value_loss           | 0.000327     |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 14       |\n",
      "|    iterations           | 6        |\n",
      "|    time_elapsed         | 210      |\n",
      "|    total_timesteps      | 3072     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | 0.938    |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 1.59e-07 |\n",
      "|    n_updates            | 50       |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 0.000186 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 14       |\n",
      "|    iterations           | 7        |\n",
      "|    time_elapsed         | 248      |\n",
      "|    total_timesteps      | 3584     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | 0.984    |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 1.6e-07  |\n",
      "|    n_updates            | 60       |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 0.000108 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 14       |\n",
      "|    iterations           | 8        |\n",
      "|    time_elapsed         | 284      |\n",
      "|    total_timesteps      | 4096     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | 1        |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 3.07e-08 |\n",
      "|    n_updates            | 70       |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 6.36e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 13       |\n",
      "|    iterations           | 9        |\n",
      "|    time_elapsed         | 329      |\n",
      "|    total_timesteps      | 4608     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | nan      |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 1.24e-08 |\n",
      "|    n_updates            | 80       |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 3.91e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 13       |\n",
      "|    iterations           | 10       |\n",
      "|    time_elapsed         | 366      |\n",
      "|    total_timesteps      | 5120     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | 1        |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 4.73e-08 |\n",
      "|    n_updates            | 90       |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 2.38e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 13       |\n",
      "|    iterations           | 11       |\n",
      "|    time_elapsed         | 403      |\n",
      "|    total_timesteps      | 5632     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | nan      |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 5.24e-09 |\n",
      "|    n_updates            | 100      |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 1.41e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 13       |\n",
      "|    iterations           | 12       |\n",
      "|    time_elapsed         | 448      |\n",
      "|    total_timesteps      | 6144     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | 1        |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 7.31e-09 |\n",
      "|    n_updates            | 110      |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 7.97e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 13       |\n",
      "|    iterations           | 13       |\n",
      "|    time_elapsed         | 486      |\n",
      "|    total_timesteps      | 6656     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | 1        |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 9.63e-09 |\n",
      "|    n_updates            | 120      |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 4.62e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 13       |\n",
      "|    iterations           | 14       |\n",
      "|    time_elapsed         | 522      |\n",
      "|    total_timesteps      | 7168     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | 1        |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 3.97e-10 |\n",
      "|    n_updates            | 130      |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 2.55e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 13       |\n",
      "|    iterations           | 15       |\n",
      "|    time_elapsed         | 566      |\n",
      "|    total_timesteps      | 7680     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | 1        |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 1.5e-09  |\n",
      "|    n_updates            | 140      |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 1.46e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 13       |\n",
      "|    iterations           | 16       |\n",
      "|    time_elapsed         | 604      |\n",
      "|    total_timesteps      | 8192     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | 1        |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 1.79e-09 |\n",
      "|    n_updates            | 150      |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 8.48e-07 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 13       |\n",
      "|    iterations           | 17       |\n",
      "|    time_elapsed         | 640      |\n",
      "|    total_timesteps      | 8704     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | 1        |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 1.08e-10 |\n",
      "|    n_updates            | 160      |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 4.68e-07 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 13       |\n",
      "|    iterations           | 18       |\n",
      "|    time_elapsed         | 686      |\n",
      "|    total_timesteps      | 9216     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | nan      |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 3.61e-10 |\n",
      "|    n_updates            | 170      |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 2.67e-07 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 13       |\n",
      "|    iterations           | 19       |\n",
      "|    time_elapsed         | 728      |\n",
      "|    total_timesteps      | 9728     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | 1        |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 3.19e-10 |\n",
      "|    n_updates            | 180      |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 1.58e-07 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 13       |\n",
      "|    iterations           | 20       |\n",
      "|    time_elapsed         | 765      |\n",
      "|    total_timesteps      | 10240    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.95    |\n",
      "|    explained_variance   | 1        |\n",
      "|    learning_rate        | 1e-06    |\n",
      "|    loss                 | 4.09e-12 |\n",
      "|    n_updates            | 190      |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 8.57e-08 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7ff50287c070>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train start #train中の値は、callbackにて定義したように、返して貰う\n",
    "model.learn(total_timesteps=10000, callback=callback)\n",
    "#1000000推奨 #https://youtu.be/2eeYqJ0uBKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9929068d-e07e-4975-b5a1-a406b9643cee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train済んだら、trainしたmodelを保存\n",
    "model.save('thisisatestmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f11bf9-9f59-47ae-b139-8b6cbbc87d8d",
   "metadata": {},
   "source": [
    "<h1>Test the Trained Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d6de491-1f75-46c9-ac6e-364c8099b39b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#xxxxxstep count分trainしたmodelをobtain by PPO.load('./train/best_model_xxxxx')\n",
    "model = PPO.load('./train/best_model_10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dde745b-6165-4ca9-b8d3-546c535793f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 19:07:41.202 python[53156:1205803] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fa483f29fa0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2023-08-02 19:07:41.203 python[53156:1205803] Warning: Expected min height of view: (<NSButton: 0x7fa48d2f3a90>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2023-08-02 19:07:41.206 python[53156:1205803] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fa48d2f3d30>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2023-08-02 19:07:41.207 python[53156:1205803] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fa48d2f3fd0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2023-08-02 19:08:01.522 python[53156:1205803] +[CATransaction synchronize] called within transaction\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6t/hr04sv895rq1vtv4yhbmxtxh0000gn/T/ipykernel_53156/2633450268.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#そしてそのactionを取った結果が出力。かつ、action起こした後のstateから上に戻って、またstart。while Trueだから無限にloop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mrendering\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVecEnvObs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# crash for subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"human\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"render\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36menv_method\u001b[0;34m(self, method_name, indices, *method_args, **method_kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;34m\"\"\"Call instance methods of vectorized environments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mtarget_envs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_target_envs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmethod_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmethod_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0menv_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_envs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0menv_is_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper_class\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVecEnvIndices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;34m\"\"\"Call instance methods of vectorized environments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mtarget_envs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_target_envs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmethod_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmethod_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0menv_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_envs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0menv_is_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper_class\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVecEnvIndices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/shimmy/openai_gym_compatibility.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mrendering\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepending\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrender\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgym_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;34m\"\"\"Renders the environment with kwargs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;34m\"\"\"Renders the environment with kwargs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;34m\"\"\"Renders the environment with kwargs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;34m\"\"\"Renders the environment with kwargs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;34m\"set `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             )\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nes_py/nes_env.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 )\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# show the screen on the image viewer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nes_py/_image_viewer.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mpitch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start the game \n",
    "state = env.reset()\n",
    "# Loop through the game\n",
    "\n",
    "while True: #while trueはbreakが入力されるまでinfiniteに繰り返される\n",
    "    \n",
    "    action, _ = model.predict(state)\n",
    "    #PPOにおけるpredict()は、1stにてpredictに基づいた次取るaction、2ndにてq-value的な(次そのaction取ったらestimatedこれくらいreward)返す\n",
    "    #PPOはsimple、今のstateから次どのaction取ったら良いかを直接予測\n",
    "    #引数のstateはnow state\n",
    "    \n",
    "    state, reward, done, info = env.step(action)\n",
    "    #そしてそのactionを取った結果が出力。かつ、action起こした後のstateから上に戻って、またstart。while Trueだから無限にloop\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7d5e8-fd48-49ca-8fe8-6582034878e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
